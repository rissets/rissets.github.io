{"componentChunkName":"component---src-pages-pensieve-index-js","path":"/pensieve/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"frontmatter":{"title":"Building a RAG System with Django and Langchain","description":"How to build a production-ready Retrieval-Augmented Generation system using Django as the backend and Langchain for orchestration.","slug":"/pensieve/rag-with-django-langchain","date":"2025-03-20","tags":["AI","Django","Langchain","LLM"],"draft":false},"html":"<h2>Introduction</h2>\n<p>Retrieval-Augmented Generation (RAG) has become the standard pattern for building LLM applications that need access to private or domain-specific knowledge. Instead of fine-tuning a model on your data (expensive, slow, inflexible), RAG retrieves relevant context at query time and feeds it to the LLM alongside the user's question.</p>\n<p>In this post, I'll walk through how to build a production-ready RAG system using <strong>Django</strong> as the backend framework and <strong>Langchain</strong> for LLM orchestration — a stack I've used extensively in building AI-powered applications.</p>\n<h2>Architecture Overview</h2>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">User Query → Django API → Langchain Pipeline → Response\n                              │\n                    ┌─────────┼──────────┐\n                    ▼         ▼          ▼\n              Embedding    Vector DB   LLM API\n              Model        (pgvector)  (Ollama/OpenAI)</code></pre></div>\n<p>The system consists of:</p>\n<ol>\n<li><strong>Django REST API</strong> — handles authentication, rate limiting, and request routing</li>\n<li><strong>Document ingestion pipeline</strong> — processes PDFs/text, chunks them, and stores embeddings</li>\n<li><strong>Retrieval engine</strong> — performs semantic search using pgvector</li>\n<li><strong>Generation layer</strong> — Langchain chains that combine retrieved context with LLM prompting</li>\n</ol>\n<h2>Setting Up the Stack</h2>\n<h3>Django Models</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># models.py</span>\n<span class=\"token keyword\">from</span> django<span class=\"token punctuation\">.</span>db <span class=\"token keyword\">import</span> models\n<span class=\"token keyword\">from</span> pgvector<span class=\"token punctuation\">.</span>django <span class=\"token keyword\">import</span> VectorField\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Document</span><span class=\"token punctuation\">(</span>models<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    title <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>CharField<span class=\"token punctuation\">(</span>max_length<span class=\"token operator\">=</span><span class=\"token number\">500</span><span class=\"token punctuation\">)</span>\n    source <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>FileField<span class=\"token punctuation\">(</span>upload_to<span class=\"token operator\">=</span><span class=\"token string\">'documents/'</span><span class=\"token punctuation\">)</span>\n    uploaded_at <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>DateTimeField<span class=\"token punctuation\">(</span>auto_now_add<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">DocumentChunk</span><span class=\"token punctuation\">(</span>models<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    document <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>ForeignKey<span class=\"token punctuation\">(</span>Document<span class=\"token punctuation\">,</span> on_delete<span class=\"token operator\">=</span>models<span class=\"token punctuation\">.</span>CASCADE<span class=\"token punctuation\">)</span>\n    content <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>TextField<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    embedding <span class=\"token operator\">=</span> VectorField<span class=\"token punctuation\">(</span>dimensions<span class=\"token operator\">=</span><span class=\"token number\">1536</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># OpenAI ada-002</span>\n    metadata <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>JSONField<span class=\"token punctuation\">(</span>default<span class=\"token operator\">=</span><span class=\"token builtin\">dict</span><span class=\"token punctuation\">)</span>\n    chunk_index <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>IntegerField<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">class</span> <span class=\"token class-name\">Meta</span><span class=\"token punctuation\">:</span>\n        indexes <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n            models<span class=\"token punctuation\">.</span>Index<span class=\"token punctuation\">(</span>fields<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'document'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">]</span></code></pre></div>\n<h3>Document Ingestion</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># services/ingestion.py</span>\n<span class=\"token keyword\">from</span> langchain<span class=\"token punctuation\">.</span>text_splitter <span class=\"token keyword\">import</span> RecursiveCharacterTextSplitter\n<span class=\"token keyword\">from</span> langchain<span class=\"token punctuation\">.</span>embeddings <span class=\"token keyword\">import</span> OpenAIEmbeddings\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">ingest_document</span><span class=\"token punctuation\">(</span>document_id<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    document <span class=\"token operator\">=</span> Document<span class=\"token punctuation\">.</span>objects<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token builtin\">id</span><span class=\"token operator\">=</span>document_id<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Load and split</span>\n    text <span class=\"token operator\">=</span> extract_text<span class=\"token punctuation\">(</span>document<span class=\"token punctuation\">.</span>source<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">)</span>\n    splitter <span class=\"token operator\">=</span> RecursiveCharacterTextSplitter<span class=\"token punctuation\">(</span>\n        chunk_size<span class=\"token operator\">=</span><span class=\"token number\">1000</span><span class=\"token punctuation\">,</span>\n        chunk_overlap<span class=\"token operator\">=</span><span class=\"token number\">200</span><span class=\"token punctuation\">,</span>\n        separators<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"\\n\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\". \"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\" \"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">)</span>\n    chunks <span class=\"token operator\">=</span> splitter<span class=\"token punctuation\">.</span>split_text<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Embed</span>\n    embeddings <span class=\"token operator\">=</span> OpenAIEmbeddings<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    vectors <span class=\"token operator\">=</span> embeddings<span class=\"token punctuation\">.</span>embed_documents<span class=\"token punctuation\">(</span>chunks<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Store</span>\n    DocumentChunk<span class=\"token punctuation\">.</span>objects<span class=\"token punctuation\">.</span>bulk_create<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n        DocumentChunk<span class=\"token punctuation\">(</span>\n            document<span class=\"token operator\">=</span>document<span class=\"token punctuation\">,</span>\n            content<span class=\"token operator\">=</span>chunk<span class=\"token punctuation\">,</span>\n            embedding<span class=\"token operator\">=</span>vector<span class=\"token punctuation\">,</span>\n            chunk_index<span class=\"token operator\">=</span>i\n        <span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>chunk<span class=\"token punctuation\">,</span> vector<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>chunks<span class=\"token punctuation\">,</span> vectors<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3>Retrieval with pgvector</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># services/retrieval.py</span>\n<span class=\"token keyword\">from</span> pgvector<span class=\"token punctuation\">.</span>django <span class=\"token keyword\">import</span> L2Distance\n<span class=\"token keyword\">from</span> langchain<span class=\"token punctuation\">.</span>embeddings <span class=\"token keyword\">import</span> OpenAIEmbeddings\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">retrieve_context</span><span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> top_k<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span> <span class=\"token operator\">=</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    embeddings <span class=\"token operator\">=</span> OpenAIEmbeddings<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    query_vector <span class=\"token operator\">=</span> embeddings<span class=\"token punctuation\">.</span>embed_query<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span>\n\n    chunks <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>\n        DocumentChunk<span class=\"token punctuation\">.</span>objects\n        <span class=\"token punctuation\">.</span>annotate<span class=\"token punctuation\">(</span>distance<span class=\"token operator\">=</span>L2Distance<span class=\"token punctuation\">(</span><span class=\"token string\">'embedding'</span><span class=\"token punctuation\">,</span> query_vector<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">.</span>order_by<span class=\"token punctuation\">(</span><span class=\"token string\">'distance'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>top_k<span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">[</span>\n        <span class=\"token punctuation\">{</span><span class=\"token string\">\"content\"</span><span class=\"token punctuation\">:</span> chunk<span class=\"token punctuation\">.</span>content<span class=\"token punctuation\">,</span> <span class=\"token string\">\"score\"</span><span class=\"token punctuation\">:</span> chunk<span class=\"token punctuation\">.</span>distance<span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">for</span> chunk <span class=\"token keyword\">in</span> chunks\n    <span class=\"token punctuation\">]</span></code></pre></div>\n<h3>The RAG Chain</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># services/rag.py</span>\n<span class=\"token keyword\">from</span> langchain<span class=\"token punctuation\">.</span>chains <span class=\"token keyword\">import</span> RetrievalQA\n<span class=\"token keyword\">from</span> langchain<span class=\"token punctuation\">.</span>prompts <span class=\"token keyword\">import</span> PromptTemplate\n<span class=\"token keyword\">from</span> langchain<span class=\"token punctuation\">.</span>llms <span class=\"token keyword\">import</span> Ollama\n\nPROMPT_TEMPLATE <span class=\"token operator\">=</span> <span class=\"token triple-quoted-string string\">\"\"\"Use the following context to answer the question.\nIf you don't know the answer, say so — don't make things up.\n\nContext:\n{context}\n\nQuestion: {question}\n\nAnswer:\"\"\"</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">generate_answer</span><span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    context_docs <span class=\"token operator\">=</span> retrieve_context<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span>\n    context <span class=\"token operator\">=</span> <span class=\"token string\">\"\\n\\n\"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>doc<span class=\"token punctuation\">[</span><span class=\"token string\">\"content\"</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> doc <span class=\"token keyword\">in</span> context_docs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    llm <span class=\"token operator\">=</span> Ollama<span class=\"token punctuation\">(</span>model<span class=\"token operator\">=</span><span class=\"token string\">\"llama3\"</span><span class=\"token punctuation\">)</span>\n    prompt <span class=\"token operator\">=</span> PromptTemplate<span class=\"token punctuation\">(</span>\n        template<span class=\"token operator\">=</span>PROMPT_TEMPLATE<span class=\"token punctuation\">,</span>\n        input_variables<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"context\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"question\"</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">)</span>\n\n    chain <span class=\"token operator\">=</span> prompt <span class=\"token operator\">|</span> llm\n    response <span class=\"token operator\">=</span> chain<span class=\"token punctuation\">.</span>invoke<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"context\"</span><span class=\"token punctuation\">:</span> context<span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"question\"</span><span class=\"token punctuation\">:</span> query\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"answer\"</span><span class=\"token punctuation\">:</span> response<span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"sources\"</span><span class=\"token punctuation\">:</span> context_docs\n    <span class=\"token punctuation\">}</span></code></pre></div>\n<h2>Django API Endpoint</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># views.py</span>\n<span class=\"token keyword\">from</span> rest_framework<span class=\"token punctuation\">.</span>views <span class=\"token keyword\">import</span> APIView\n<span class=\"token keyword\">from</span> rest_framework<span class=\"token punctuation\">.</span>response <span class=\"token keyword\">import</span> Response\n<span class=\"token keyword\">from</span> rest_framework<span class=\"token punctuation\">.</span>permissions <span class=\"token keyword\">import</span> IsAuthenticated\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">RAGQueryView</span><span class=\"token punctuation\">(</span>APIView<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    permission_classes <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>IsAuthenticated<span class=\"token punctuation\">]</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">post</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> request<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        query <span class=\"token operator\">=</span> request<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">\"query\"</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> query<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> Response<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span><span class=\"token string\">\"error\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Query is required\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span> status<span class=\"token operator\">=</span><span class=\"token number\">400</span><span class=\"token punctuation\">)</span>\n\n        result <span class=\"token operator\">=</span> generate_answer<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> Response<span class=\"token punctuation\">(</span>result<span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Production Considerations</h2>\n<h3>1. Chunking Strategy Matters</h3>\n<p>The quality of your RAG system depends heavily on how you split documents. We found that:</p>\n<ul>\n<li><strong>1000 tokens per chunk</strong> with <strong>200 token overlap</strong> works well for most documents</li>\n<li>Using semantic boundaries (paragraphs, sections) preserves context better than fixed-size splits</li>\n<li>Metadata-enriched chunks (source, page number, section title) improve retrieval quality</li>\n</ul>\n<h3>2. Hybrid Search</h3>\n<p>Pure vector similarity search can miss keyword-specific matches. We combine:</p>\n<ul>\n<li><strong>Semantic search</strong> (pgvector) for conceptual similarity</li>\n<li><strong>Full-text search</strong> (PostgreSQL <code class=\"language-text\">tsvector</code>) for keyword matching</li>\n<li><strong>Reciprocal Rank Fusion</strong> to combine results</li>\n</ul>\n<h3>3. Caching</h3>\n<p>For repeated queries, we cache embeddings and responses using Redis with a TTL:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> hashlib\n<span class=\"token keyword\">from</span> django<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>cache <span class=\"token keyword\">import</span> cache\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">cached_generate</span><span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    cache_key <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"rag:</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>hashlib<span class=\"token punctuation\">.</span>md5<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>hexdigest<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span>\n    cached <span class=\"token operator\">=</span> cache<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span>cache_key<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span> cached<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> cached\n\n    result <span class=\"token operator\">=</span> generate_answer<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span>\n    cache<span class=\"token punctuation\">.</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>cache_key<span class=\"token punctuation\">,</span> result<span class=\"token punctuation\">,</span> timeout<span class=\"token operator\">=</span><span class=\"token number\">3600</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> result</code></pre></div>\n<h3>4. Evaluation</h3>\n<p>We use RAGAS metrics to evaluate retrieval quality: faithfulness, answer relevancy, and context precision. This helps us tune chunk size, overlap, and retrieval parameters.</p>\n<h2>Conclusion</h2>\n<p>Django + Langchain is a powerful combination for building production RAG systems. Django handles the \"boring but essential\" parts (auth, admin, ORM, migrations) while Langchain provides the LLM orchestration layer. With pgvector, you get a vector database without adding another service to your stack.</p>\n<hr>\n<p><em>This post is based on my experience building AI systems at Orbit Tech Solution and Bagus Harapan Tritunggal.</em></p>"}},{"node":{"frontmatter":{"title":"Physics-Informed Neural Networks: Bridging Physics and Deep Learning","description":"A deep dive into PINNs — how we combined physics engines with neural networks to predict ball trajectory in a hyper-realistic golf simulator.","slug":"/pensieve/physics-informed-neural-networks","date":"2024-11-15","tags":["Machine Learning","Physics","PyTorch","PINNs"],"draft":false},"html":"<h2>Introduction</h2>\n<p>Physics-Informed Neural Networks (PINNs) represent a paradigm shift in how we approach problems that lie at the intersection of physics and machine learning. Rather than treating neural networks as black boxes that learn purely from data, PINNs encode the fundamental laws of physics directly into the loss function — ensuring that predictions remain physically consistent.</p>\n<p>In this post, I'll share my experience building the core engine for <strong>Fairway Golf Simulator</strong>, where we used PINNs combined with traditional ANNs to predict golf ball trajectory with remarkable accuracy.</p>\n<h2>The Problem</h2>\n<p>Golf ball physics is deceptively complex. A ball in flight is affected by:</p>\n<ul>\n<li><strong>Gravity</strong> — the constant downward acceleration</li>\n<li><strong>Aerodynamic drag</strong> — resistance proportional to velocity squared</li>\n<li><strong>Magnus effect</strong> — spin-induced lift that causes hooks and slices</li>\n<li><strong>Wind</strong> — external force vectors varying by altitude</li>\n<li><strong>Ground interaction</strong> — bounce, roll, and friction on landing</li>\n</ul>\n<p>Traditional physics engines can model these forces, but they require precise initial conditions and material properties that are difficult to measure in practice. Pure data-driven approaches, on the other hand, require enormous datasets and often produce physically implausible predictions.</p>\n<h2>Why PINNs?</h2>\n<p>PINNs offer the best of both worlds. The key insight is embedding the governing differential equations directly into the neural network's training process.</p>\n<p>For a golf ball in flight, the equations of motion are:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">m * d²x/dt² = F_drag_x + F_magnus_x + F_wind_x\nm * d²y/dt² = F_drag_y + F_magnus_y + F_wind_y - m*g\nm * d²z/dt² = F_drag_z + F_magnus_z + F_wind_z</code></pre></div>\n<p>In a PINN framework, we define a composite loss function:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">loss <span class=\"token operator\">=</span> loss_data <span class=\"token operator\">+</span> lambda_physics <span class=\"token operator\">*</span> loss_physics\n\n<span class=\"token comment\"># loss_data: MSE between predictions and observed trajectories</span>\n<span class=\"token comment\"># loss_physics: Residual of the governing PDEs evaluated at collocation points</span></code></pre></div>\n<p>The physics loss acts as a regularizer, ensuring the network's predictions satisfy physical laws even in regions with sparse training data.</p>\n<h2>Architecture</h2>\n<p>Our implementation used PyTorch with the following architecture:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">GolfPINN</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>net <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\n            nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">128</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>      <span class=\"token comment\"># Input: time t</span>\n            nn<span class=\"token punctuation\">.</span>Tanh<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> <span class=\"token number\">128</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            nn<span class=\"token punctuation\">.</span>Tanh<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> <span class=\"token number\">128</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            nn<span class=\"token punctuation\">.</span>Tanh<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>      <span class=\"token comment\"># Output: x, y, z, vx, vy, vz</span>\n        <span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> t<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>net<span class=\"token punctuation\">(</span>t<span class=\"token punctuation\">)</span></code></pre></div>\n<p>The physics residual is computed using automatic differentiation:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">physics_loss</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> t<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    t<span class=\"token punctuation\">.</span>requires_grad_<span class=\"token punctuation\">(</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    output <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>t<span class=\"token punctuation\">)</span>\n    x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> z <span class=\"token operator\">=</span> output<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> output<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> output<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">:</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span>\n    vx<span class=\"token punctuation\">,</span> vy<span class=\"token punctuation\">,</span> vz <span class=\"token operator\">=</span> output<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">:</span><span class=\"token number\">4</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> output<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">:</span><span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> output<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">:</span><span class=\"token number\">6</span><span class=\"token punctuation\">]</span>\n\n    <span class=\"token comment\"># Compute accelerations via autograd</span>\n    ax <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>autograd<span class=\"token punctuation\">.</span>grad<span class=\"token punctuation\">(</span>vx<span class=\"token punctuation\">,</span> t<span class=\"token punctuation\">,</span> torch<span class=\"token punctuation\">.</span>ones_like<span class=\"token punctuation\">(</span>vx<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> create_graph<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n    ay <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>autograd<span class=\"token punctuation\">.</span>grad<span class=\"token punctuation\">(</span>vy<span class=\"token punctuation\">,</span> t<span class=\"token punctuation\">,</span> torch<span class=\"token punctuation\">.</span>ones_like<span class=\"token punctuation\">(</span>vy<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> create_graph<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n    az <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>autograd<span class=\"token punctuation\">.</span>grad<span class=\"token punctuation\">(</span>vz<span class=\"token punctuation\">,</span> t<span class=\"token punctuation\">,</span> torch<span class=\"token punctuation\">.</span>ones_like<span class=\"token punctuation\">(</span>vz<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> create_graph<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n\n    <span class=\"token comment\"># Physics: F = ma</span>\n    drag <span class=\"token operator\">=</span> compute_drag<span class=\"token punctuation\">(</span>vx<span class=\"token punctuation\">,</span> vy<span class=\"token punctuation\">,</span> vz<span class=\"token punctuation\">)</span>\n    magnus <span class=\"token operator\">=</span> compute_magnus<span class=\"token punctuation\">(</span>vx<span class=\"token punctuation\">,</span> vy<span class=\"token punctuation\">,</span> vz<span class=\"token punctuation\">,</span> spin<span class=\"token punctuation\">)</span>\n\n    residual_x <span class=\"token operator\">=</span> ax <span class=\"token operator\">-</span> <span class=\"token punctuation\">(</span>drag<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> magnus<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> mass\n    residual_y <span class=\"token operator\">=</span> ay <span class=\"token operator\">-</span> <span class=\"token punctuation\">(</span>drag<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> magnus<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">-</span> g<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> mass\n    residual_z <span class=\"token operator\">=</span> az <span class=\"token operator\">-</span> <span class=\"token punctuation\">(</span>drag<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> magnus<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> mass\n\n    <span class=\"token keyword\">return</span> torch<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>residual_x<span class=\"token operator\">**</span><span class=\"token number\">2</span> <span class=\"token operator\">+</span> residual_y<span class=\"token operator\">**</span><span class=\"token number\">2</span> <span class=\"token operator\">+</span> residual_z<span class=\"token operator\">**</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Results</h2>\n<p>The PINN model achieved significantly better generalization compared to a pure data-driven ANN, especially for:</p>\n<ul>\n<li><strong>Extreme spin conditions</strong> — where training data was sparse</li>\n<li><strong>Variable wind scenarios</strong> — the physics constraint ensured realistic deflection</li>\n<li><strong>Long-range predictions</strong> — error accumulation was much lower than pure ANNs</li>\n</ul>\n<p>The combined system now powers the Fairway Simulator, processing player input in real-time to predict trajectory with high fidelity.</p>\n<h2>Key Takeaways</h2>\n<ol>\n<li><strong>PINNs shine when data is limited</strong> — physics constraints act as powerful regularizers</li>\n<li><strong>Automatic differentiation is the secret weapon</strong> — PyTorch's autograd makes computing PDE residuals trivial</li>\n<li><strong>The physics loss weight (λ) matters</strong> — too low and you lose physical consistency, too high and you underfit the data</li>\n<li><strong>Hybrid approaches work best</strong> — we used PINNs for trajectory prediction and traditional ANNs for player skill assessment</li>\n</ol>\n<h2>What's Next</h2>\n<p>We're exploring adaptive collocation point sampling and multi-fidelity PINNs to further improve accuracy while reducing training time. The framework generalizes well beyond golf — any domain where physics models exist but data is scarce can benefit from this approach.</p>\n<hr>\n<p><em>This post is based on my work at Orbit Tech Solution building the Fairway Golf Engine.</em></p>"}},{"node":{"frontmatter":{"title":"Building a Real-World Asset Tokenization Platform with Django and Web3","description":"Lessons learned from architecting Karpous — a hybrid centralized/decentralized platform for tokenizing real-world assets using Django and Web3.","slug":"/pensieve/rwa-tokenization-django-web3","date":"2024-06-10","tags":["Django","Web3","Blockchain","Crypto"],"draft":false},"html":"<h2>Introduction</h2>\n<p>Real-World Asset (RWA) tokenization is one of the most compelling use cases for blockchain technology — representing physical assets like real estate, commodities, or intellectual property as digital tokens on a blockchain. This unlocks fractional ownership, 24/7 trading, and programmable compliance.</p>\n<p>I led the backend architecture for <strong>Karpous</strong>, a platform that enables users to invest in tokenized real-world assets. The biggest technical challenge? Building a hybrid system that seamlessly bridges traditional web infrastructure (Django, PostgreSQL) with decentralized blockchain protocols (Web3, MetaMask, smart contracts).</p>\n<h2>Architecture: Centralized Meets Decentralized</h2>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">┌────────────────────────────────────────────────┐\n│                  Frontend (React)                │\n├────────────────────────────────────────────────┤\n│              Django REST Backend                 │\n│  ┌──────────┐  ┌──────────┐  ┌──────────────┐ │\n│  │ Auth &amp;   │  │ Asset    │  │ Transaction  │ │\n│  │ KYC      │  │ Manager  │  │ Engine       │ │\n│  └──────────┘  └──────────┘  └──────────────┘ │\n├────────────────────────────────────────────────┤\n│              Blockchain Layer                    │\n│  ┌──────────┐  ┌──────────┐  ┌──────────────┐ │\n│  │ Web3.py  │  │ Smart    │  │ MetaMask     │ │\n│  │ Gateway  │  │ Contracts│  │ Integration  │ │\n│  └──────────┘  └──────────┘  └──────────────┘ │\n├────────────────────────────────────────────────┤\n│  PostgreSQL  │  Redis  │  gRPC Services        │\n└────────────────────────────────────────────────┘</code></pre></div>\n<h2>The Hybrid Challenge</h2>\n<p>The fundamental tension in RWA platforms is: blockchain transactions are immutable and asynchronous, while your Django app expects synchronous, reversible database operations.</p>\n<h3>Transaction States</h3>\n<p>We needed a state machine to track the lifecycle of every tokenization event:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">TokenTransaction</span><span class=\"token punctuation\">(</span>models<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">class</span> <span class=\"token class-name\">Status</span><span class=\"token punctuation\">(</span>models<span class=\"token punctuation\">.</span>TextChoices<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        PENDING <span class=\"token operator\">=</span> <span class=\"token string\">'pending'</span>          <span class=\"token comment\"># Created in Django</span>\n        SUBMITTED <span class=\"token operator\">=</span> <span class=\"token string\">'submitted'</span>      <span class=\"token comment\"># Sent to blockchain</span>\n        CONFIRMING <span class=\"token operator\">=</span> <span class=\"token string\">'confirming'</span>    <span class=\"token comment\"># Waiting for confirmations</span>\n        CONFIRMED <span class=\"token operator\">=</span> <span class=\"token string\">'confirmed'</span>      <span class=\"token comment\"># On-chain confirmed</span>\n        FAILED <span class=\"token operator\">=</span> <span class=\"token string\">'failed'</span>            <span class=\"token comment\"># Transaction reverted</span>\n\n    asset <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>ForeignKey<span class=\"token punctuation\">(</span><span class=\"token string\">'Asset'</span><span class=\"token punctuation\">,</span> on_delete<span class=\"token operator\">=</span>models<span class=\"token punctuation\">.</span>PROTECT<span class=\"token punctuation\">)</span>\n    user <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>ForeignKey<span class=\"token punctuation\">(</span><span class=\"token string\">'User'</span><span class=\"token punctuation\">,</span> on_delete<span class=\"token operator\">=</span>models<span class=\"token punctuation\">.</span>PROTECT<span class=\"token punctuation\">)</span>\n    tx_hash <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>CharField<span class=\"token punctuation\">(</span>max_length<span class=\"token operator\">=</span><span class=\"token number\">66</span><span class=\"token punctuation\">,</span> null<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> blank<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    status <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>CharField<span class=\"token punctuation\">(</span>max_length<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> choices<span class=\"token operator\">=</span>Status<span class=\"token punctuation\">.</span>choices<span class=\"token punctuation\">)</span>\n    amount <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>DecimalField<span class=\"token punctuation\">(</span>max_digits<span class=\"token operator\">=</span><span class=\"token number\">24</span><span class=\"token punctuation\">,</span> decimal_places<span class=\"token operator\">=</span><span class=\"token number\">8</span><span class=\"token punctuation\">)</span>\n    created_at <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>DateTimeField<span class=\"token punctuation\">(</span>auto_now_add<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    confirmed_at <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>DateTimeField<span class=\"token punctuation\">(</span>null<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3>Web3 Integration</h3>\n<p>We built a gateway service to interact with smart contracts:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># services/web3_gateway.py</span>\n<span class=\"token keyword\">from</span> web3 <span class=\"token keyword\">import</span> Web3\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Web3Gateway</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>w3 <span class=\"token operator\">=</span> Web3<span class=\"token punctuation\">(</span>Web3<span class=\"token punctuation\">.</span>HTTPProvider<span class=\"token punctuation\">(</span>settings<span class=\"token punctuation\">.</span>RPC_URL<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>contract <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>w3<span class=\"token punctuation\">.</span>eth<span class=\"token punctuation\">.</span>contract<span class=\"token punctuation\">(</span>\n            address<span class=\"token operator\">=</span>settings<span class=\"token punctuation\">.</span>TOKEN_CONTRACT_ADDRESS<span class=\"token punctuation\">,</span>\n            abi<span class=\"token operator\">=</span>TOKEN_ABI\n        <span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">mint_tokens</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> to_address<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> amount<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">,</span> asset_id<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"Mint RWA tokens to a user's wallet.\"\"\"</span>\n        tx <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>contract<span class=\"token punctuation\">.</span>functions<span class=\"token punctuation\">.</span>mint<span class=\"token punctuation\">(</span>\n            to_address<span class=\"token punctuation\">,</span> amount<span class=\"token punctuation\">,</span> asset_id\n        <span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>build_transaction<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span>\n            <span class=\"token string\">'from'</span><span class=\"token punctuation\">:</span> settings<span class=\"token punctuation\">.</span>ADMIN_WALLET<span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'nonce'</span><span class=\"token punctuation\">:</span> self<span class=\"token punctuation\">.</span>w3<span class=\"token punctuation\">.</span>eth<span class=\"token punctuation\">.</span>get_transaction_count<span class=\"token punctuation\">(</span>\n                settings<span class=\"token punctuation\">.</span>ADMIN_WALLET\n            <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'gas'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">200000</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'gasPrice'</span><span class=\"token punctuation\">:</span> self<span class=\"token punctuation\">.</span>w3<span class=\"token punctuation\">.</span>eth<span class=\"token punctuation\">.</span>gas_price<span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n\n        signed <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>w3<span class=\"token punctuation\">.</span>eth<span class=\"token punctuation\">.</span>account<span class=\"token punctuation\">.</span>sign_transaction<span class=\"token punctuation\">(</span>\n            tx<span class=\"token punctuation\">,</span> settings<span class=\"token punctuation\">.</span>ADMIN_PRIVATE_KEY\n        <span class=\"token punctuation\">)</span>\n        tx_hash <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>w3<span class=\"token punctuation\">.</span>eth<span class=\"token punctuation\">.</span>send_raw_transaction<span class=\"token punctuation\">(</span>\n            signed<span class=\"token punctuation\">.</span>raw_transaction\n        <span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> tx_hash<span class=\"token punctuation\">.</span><span class=\"token builtin\">hex</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3>The Confirmation Problem</h3>\n<p>Blockchain transactions aren't instant. We used Celery workers to poll for confirmations:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># tasks.py</span>\n<span class=\"token keyword\">from</span> celery <span class=\"token keyword\">import</span> shared_task\n\n<span class=\"token decorator annotation punctuation\">@shared_task</span><span class=\"token punctuation\">(</span>bind<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> max_retries<span class=\"token operator\">=</span><span class=\"token number\">50</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">check_transaction_confirmation</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> transaction_id<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    tx <span class=\"token operator\">=</span> TokenTransaction<span class=\"token punctuation\">.</span>objects<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token builtin\">id</span><span class=\"token operator\">=</span>transaction_id<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n        receipt <span class=\"token operator\">=</span> web3_gateway<span class=\"token punctuation\">.</span>w3<span class=\"token punctuation\">.</span>eth<span class=\"token punctuation\">.</span>get_transaction_receipt<span class=\"token punctuation\">(</span>tx<span class=\"token punctuation\">.</span>tx_hash<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">if</span> receipt <span class=\"token keyword\">is</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n            <span class=\"token comment\"># Not mined yet — retry in 15 seconds</span>\n            <span class=\"token keyword\">raise</span> self<span class=\"token punctuation\">.</span>retry<span class=\"token punctuation\">(</span>countdown<span class=\"token operator\">=</span><span class=\"token number\">15</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">if</span> receipt<span class=\"token punctuation\">[</span><span class=\"token string\">'status'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n            tx<span class=\"token punctuation\">.</span>status <span class=\"token operator\">=</span> TokenTransaction<span class=\"token punctuation\">.</span>Status<span class=\"token punctuation\">.</span>CONFIRMED\n            tx<span class=\"token punctuation\">.</span>confirmed_at <span class=\"token operator\">=</span> timezone<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            tx<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            notify_user_confirmation<span class=\"token punctuation\">(</span>tx<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            tx<span class=\"token punctuation\">.</span>status <span class=\"token operator\">=</span> TokenTransaction<span class=\"token punctuation\">.</span>Status<span class=\"token punctuation\">.</span>FAILED\n            tx<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            handle_failed_transaction<span class=\"token punctuation\">(</span>tx<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">except</span> TransactionNotFound<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">raise</span> self<span class=\"token punctuation\">.</span>retry<span class=\"token punctuation\">(</span>countdown<span class=\"token operator\">=</span><span class=\"token number\">15</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Security Considerations</h2>\n<h3>Wallet Verification</h3>\n<p>Users connect their MetaMask wallet and sign a message to prove ownership:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># views.py</span>\n<span class=\"token keyword\">from</span> eth_account<span class=\"token punctuation\">.</span>messages <span class=\"token keyword\">import</span> defunct_hash_message\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">WalletVerifyView</span><span class=\"token punctuation\">(</span>APIView<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">post</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> request<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        address <span class=\"token operator\">=</span> request<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">[</span><span class=\"token string\">'address'</span><span class=\"token punctuation\">]</span>\n        signature <span class=\"token operator\">=</span> request<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">[</span><span class=\"token string\">'signature'</span><span class=\"token punctuation\">]</span>\n        message <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"Verify wallet for Karpous: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>request<span class=\"token punctuation\">.</span>user<span class=\"token punctuation\">.</span><span class=\"token builtin\">id</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span>\n\n        <span class=\"token comment\"># Recover signer address from signature</span>\n        message_hash <span class=\"token operator\">=</span> defunct_hash_message<span class=\"token punctuation\">(</span>text<span class=\"token operator\">=</span>message<span class=\"token punctuation\">)</span>\n        recovered <span class=\"token operator\">=</span> w3<span class=\"token punctuation\">.</span>eth<span class=\"token punctuation\">.</span>account<span class=\"token punctuation\">.</span>recover_message<span class=\"token punctuation\">(</span>\n            message_hash<span class=\"token punctuation\">,</span> signature<span class=\"token operator\">=</span>signature\n        <span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">if</span> recovered<span class=\"token punctuation\">.</span>lower<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> address<span class=\"token punctuation\">.</span>lower<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            request<span class=\"token punctuation\">.</span>user<span class=\"token punctuation\">.</span>wallet_address <span class=\"token operator\">=</span> address\n            request<span class=\"token punctuation\">.</span>user<span class=\"token punctuation\">.</span>wallet_verified <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>\n            request<span class=\"token punctuation\">.</span>user<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">return</span> Response<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span><span class=\"token string\">\"status\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"verified\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> Response<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span><span class=\"token string\">\"error\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Invalid signature\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span> status<span class=\"token operator\">=</span><span class=\"token number\">400</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3>Double-Spend Prevention</h3>\n<p>We use database-level locking to prevent race conditions:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> django<span class=\"token punctuation\">.</span>db <span class=\"token keyword\">import</span> transaction\n\n<span class=\"token decorator annotation punctuation\">@transaction<span class=\"token punctuation\">.</span>atomic</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">purchase_tokens</span><span class=\"token punctuation\">(</span>user<span class=\"token punctuation\">,</span> asset<span class=\"token punctuation\">,</span> amount<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    asset <span class=\"token operator\">=</span> Asset<span class=\"token punctuation\">.</span>objects<span class=\"token punctuation\">.</span>select_for_update<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token builtin\">id</span><span class=\"token operator\">=</span>asset<span class=\"token punctuation\">.</span><span class=\"token builtin\">id</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">if</span> asset<span class=\"token punctuation\">.</span>available_supply <span class=\"token operator\">&lt;</span> amount<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">raise</span> InsufficientSupplyError<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    asset<span class=\"token punctuation\">.</span>available_supply <span class=\"token operator\">-=</span> amount\n    asset<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    tx <span class=\"token operator\">=</span> TokenTransaction<span class=\"token punctuation\">.</span>objects<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span>\n        user<span class=\"token operator\">=</span>user<span class=\"token punctuation\">,</span> asset<span class=\"token operator\">=</span>asset<span class=\"token punctuation\">,</span>\n        amount<span class=\"token operator\">=</span>amount<span class=\"token punctuation\">,</span> status<span class=\"token operator\">=</span><span class=\"token string\">'pending'</span>\n    <span class=\"token punctuation\">)</span>\n\n    tx_hash <span class=\"token operator\">=</span> web3_gateway<span class=\"token punctuation\">.</span>mint_tokens<span class=\"token punctuation\">(</span>\n        user<span class=\"token punctuation\">.</span>wallet_address<span class=\"token punctuation\">,</span> amount<span class=\"token punctuation\">,</span> asset<span class=\"token punctuation\">.</span><span class=\"token builtin\">id</span>\n    <span class=\"token punctuation\">)</span>\n    tx<span class=\"token punctuation\">.</span>tx_hash <span class=\"token operator\">=</span> tx_hash\n    tx<span class=\"token punctuation\">.</span>status <span class=\"token operator\">=</span> <span class=\"token string\">'submitted'</span>\n    tx<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    check_transaction_confirmation<span class=\"token punctuation\">.</span>delay<span class=\"token punctuation\">(</span>tx<span class=\"token punctuation\">.</span><span class=\"token builtin\">id</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> tx</code></pre></div>\n<h2>gRPC for Internal Services</h2>\n<p>For high-frequency internal communication between microservices, we used gRPC instead of REST:</p>\n<div class=\"gatsby-highlight\" data-language=\"protobuf\"><pre class=\"language-protobuf\"><code class=\"language-protobuf\"><span class=\"token keyword\">service</span> <span class=\"token class-name\">AssetService</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">rpc</span> <span class=\"token function\">GetAssetPrice</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">AssetRequest</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">returns</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">PriceResponse</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">rpc</span> <span class=\"token function\">StreamPriceUpdates</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">AssetRequest</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">returns</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">stream</span> <span class=\"token class-name\">PriceResponse</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>This gave us ~10x lower latency compared to REST for price feed updates.</p>\n<h2>Lessons Learned</h2>\n<ol>\n<li><strong>Never trust the frontend for blockchain state</strong> — always verify on-chain</li>\n<li><strong>Idempotency is critical</strong> — network failures mean you might submit a transaction twice</li>\n<li><strong>Gas estimation is tricky</strong> — always add a buffer and implement retry logic</li>\n<li><strong>Test on testnets extensively</strong> — mainnet debugging is expensive</li>\n<li><strong>Separate hot and cold wallets</strong> — the admin wallet for minting should have limited funds</li>\n</ol>\n<h2>Conclusion</h2>\n<p>Building Karpous taught me that the hardest part of Web3 development isn't the blockchain itself — it's the glue between your traditional backend and the decentralized world. Django's robust ORM, transaction management, and async task processing (Celery) make it an excellent foundation for hybrid Web3 applications.</p>\n<hr>\n<p><em>This post is based on my work at Orbit Tech Solution building the Karpous RWA platform.</em></p>"}},{"node":{"frontmatter":{"title":"Docker Compose Error","description":"docker-compose version discrepancies","slug":"/pensieve/docker-error","date":"2019-12-13","tags":["WordPress","Docker"],"draft":false},"html":"<h2>Problem</h2>\n<p>Recently while updating with <a href=\"https://github.com/Upstatement/skela-wp-theme\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Skela</a> with webpack, I encountered a weird error where I wasn't able to run a simple script:</p>\n<div class=\"gatsby-code-title\">bin/composer</div>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token shebang important\">#!/bin/bash</span>\n<span class=\"token function\">docker-compose</span> <span class=\"token builtin class-name\">exec</span> <span class=\"token parameter variable\">-w</span> /var/www/html/wp-content/themes/skela wordpress <span class=\"token function\">composer</span> <span class=\"token string\">\"<span class=\"token variable\">$@</span>\"</span></code></pre></div>\n<p>When trying to run this script via <code class=\"language-text\">./bin/composer install</code>, I got this error in my terminal:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">ERROR: Setting workdir <span class=\"token keyword\">for</span> <span class=\"token builtin class-name\">exec</span> is not supported <span class=\"token keyword\">in</span> API <span class=\"token operator\">&lt;</span> <span class=\"token number\">1.35</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1.30</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>The error was coming from the <code class=\"language-text\">-w</code> flag in the <code class=\"language-text\">docker-compose exec</code> command in the <code class=\"language-text\">composer</code> script.</p>\n<h2>Solution</h2>\n<p>Turns The fix was to update the version in my <code class=\"language-text\">docker-compose.yml</code> file to from version <code class=\"language-text\">3.5</code> to <code class=\"language-text\">3.6</code>. It's strange because 3.5 isn't anywhere close to the API version <code class=\"language-text\">1.35</code> from the error message 🤷‍♀️</p>\n<div class=\"gatsby-code-title\">docker-compose.yml</div>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"gatsby-highlight-code-line\"><span class=\"token key atrule\">version</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'3.6'</span></span><span class=\"token key atrule\">services</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">wordpress</span><span class=\"token punctuation\">:</span>\n    build<span class=\"token punctuation\">:</span></code></pre></div>"}},{"node":{"frontmatter":{"title":"WordPress Publishing Error","description":"Trying to create a simple post in WordPress","slug":"/pensieve/wordpress-publish-error","date":"2019-12-03","tags":["WordPress"],"draft":false},"html":"<h2>Problem</h2>\n<p>Recently while working on a WordPress project with <a href=\"https://github.com/Upstatement/ups-dock\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Ups Dock</a>, I encountered a weird error where I wasn't able to update or publish a simple post in my local WP admin.</p>\n<p>It looked something like this:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 700px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/9a7943feb3c4ee95b43801cfda486beb/8e621/draft-fail.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 32.57142857142857%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAABYlAAAWJQFJUiTwAAABBElEQVR42qVQu07EMBD05/J3SDTUdBRUiKvggnK5PC/B8Tk5r5/DOhINQmkYaWSvdnc8HkFECN7DWYuUElKMG7nY5UoemhxgDR4PJe7uX/Dw9Awhj5+gukbsBwRmuozwXQ/XtLs01Rlj06FqB7S8044SUl0heharyxJyGDB1HU5FATWOgHOIxiDxD34zMnN/Vhrv5xaX6WtzHZmiYZGPY4GKhU/86uvbAXKekZEj2INj0XVZtjnyEXK1ECEEWM7PWscDnCXneWNnIef4B/I8kUXkPvGeZkHD53RdsHCmIjfykGfmu/dhq/fw4zw71FpDyRmezPZtgX8gGzCc56oUbhwTGYNvRIsfDCxjw1gAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Draft fail\"\n        title=\"\"\n        src=\"/static/9a7943feb3c4ee95b43801cfda486beb/39600/draft-fail.png\"\n        srcset=\"/static/9a7943feb3c4ee95b43801cfda486beb/1aaec/draft-fail.png 175w,\n/static/9a7943feb3c4ee95b43801cfda486beb/98287/draft-fail.png 350w,\n/static/9a7943feb3c4ee95b43801cfda486beb/39600/draft-fail.png 700w,\n/static/9a7943feb3c4ee95b43801cfda486beb/57cd1/draft-fail.png 1050w,\n/static/9a7943feb3c4ee95b43801cfda486beb/4af54/draft-fail.png 1400w,\n/static/9a7943feb3c4ee95b43801cfda486beb/8e621/draft-fail.png 2234w\"\n        sizes=\"(max-width: 700px) 100vw, 700px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>Sometimes the error message would be slightly more helpful: <code class=\"language-text\">Publishing failed. Error message: The response is not a valid JSON response.</code></p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 700px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/c2362fe43c3b6f9628b1cc63d0bb00f9/04410/publish-error.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 12%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAc0lEQVR42i2Oaw6DMAyDuf/dqChtaFqGEK/x2KYdwSQRPz4lTmzJ1a/vsVOHM7Hxyfmh4GTGtxTTl8FQv6L3i7Nl9X9I9v8aUGloahosvsXSBmyB8CbCFglD7Ww/uiQej9l707to9a4xYg0yQ8TonBRKuAFq8Y7nU3DtiQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Publish error\"\n        title=\"\"\n        src=\"/static/c2362fe43c3b6f9628b1cc63d0bb00f9/39600/publish-error.png\"\n        srcset=\"/static/c2362fe43c3b6f9628b1cc63d0bb00f9/1aaec/publish-error.png 175w,\n/static/c2362fe43c3b6f9628b1cc63d0bb00f9/98287/publish-error.png 350w,\n/static/c2362fe43c3b6f9628b1cc63d0bb00f9/39600/publish-error.png 700w,\n/static/c2362fe43c3b6f9628b1cc63d0bb00f9/04410/publish-error.png 956w\"\n        sizes=\"(max-width: 700px) 100vw, 700px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>And if I popped open the console, I saw these errors:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 700px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/0dc960ad57313c7b34df2794f8954458/fb77c/console-errors.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 20.571428571428573%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAABYlAAAWJQFJUiTwAAAA2klEQVR42k2PS4+CMBSFSVy4MoEMMUwUEHzs3LhxEsZk0JkWoYDz/3/M8StuXNyc9va8Gvx8xGo3G9kslQHrNFV/OOiWZarBa1nKFIW63U52u1W73+uXtz92rd+B0565JJ8KvhYLjSyb5VID4n9II+PxgWHvhVk+cfo8lyO0xXCEO3DuGVcWuqA/h6GCaxipoZVNEnUQzXqtB2bNaiVDqn034O7H8nbH3BfwIV3x4lRRpOA0n2uE0DENLRwCh+FAO8f3DGG+lUN4R+QQe5xC4FZxrIp23+BxNtMTpEZ48rdeozIAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Console errors\"\n        title=\"\"\n        src=\"/static/0dc960ad57313c7b34df2794f8954458/39600/console-errors.png\"\n        srcset=\"/static/0dc960ad57313c7b34df2794f8954458/1aaec/console-errors.png 175w,\n/static/0dc960ad57313c7b34df2794f8954458/98287/console-errors.png 350w,\n/static/0dc960ad57313c7b34df2794f8954458/39600/console-errors.png 700w,\n/static/0dc960ad57313c7b34df2794f8954458/57cd1/console-errors.png 1050w,\n/static/0dc960ad57313c7b34df2794f8954458/fb77c/console-errors.png 1185w\"\n        sizes=\"(max-width: 700px) 100vw, 700px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h2>Solution</h2>\n<p>Since the error message had to do with a JSON response, I initially thought it was a Gutenberg or ACF issue. But it turned out this was happening because I was on the https WP admin (i.e. <a href=\"https://project.ups.dock/wp-admin\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://project.ups.dock/wp-admin</a>), not the unsecure WP admin (<a href=\"http://project.ups.dock/wp-admin\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">http://project.ups.dock/wp-admin</a>).</p>\n<p>It was a CORS error!! I was trying to modify a non-https domain from a https domain. Switching to a non-https WP admin allowed me to publish posts with no problem.</p>"}}]}},"pageContext":{}},"staticQueryHashes":["3115057458"],"slicesMap":{}}
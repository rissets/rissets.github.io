{"componentChunkName":"component---src-templates-post-js","path":"/pensieve/computer-vision-production/","result":{"data":{"markdownRemark":{"html":"<h2>Introduction</h2>\n<p>Deploying computer vision systems into production is a fundamentally different challenge from training a model that performs well on a benchmark. At Pt Bagus Harapan Tritunggal, I had the opportunity to build two distinct production CV systems: an <strong>Enterprise Face Recognition API</strong> for biometric verification and a <strong>Fish Recognition System</strong> for KNMP (National Fisheries Management Council). This post captures the key lessons and architectural decisions from both projects.</p>\n<h2>The Gap Between Research and Production</h2>\n<p>A model with 99% accuracy on your test set can fail spectacularly in production due to:</p>\n<ul>\n<li><strong>Distribution shift</strong> — real-world images differ from training data (lighting, angle, occlusion)</li>\n<li><strong>Adversarial inputs</strong> — deliberate attempts to fool the system (especially critical for biometrics)</li>\n<li><strong>Latency constraints</strong> — users expect responses in milliseconds, not seconds</li>\n<li><strong>Throughput requirements</strong> — handling concurrent requests at scale</li>\n</ul>\n<h3>Face Recognition: Security-Critical Deployment</h3>\n<p>The face recognition system required not just high accuracy, but <strong>anti-spoofing</strong> capabilities — the ability to distinguish a live face from a photograph or video replay attack. This added an entire layer of complexity to the pipeline.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">FaceVerificationPipeline</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># Detection: Ultralytics YOLO for face detection</span>\n        self<span class=\"token punctuation\">.</span>detector <span class=\"token operator\">=</span> YOLO<span class=\"token punctuation\">(</span><span class=\"token string\">'face_detection.pt'</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Recognition: InsightFace for face embeddings</span>\n        self<span class=\"token punctuation\">.</span>recognizer <span class=\"token operator\">=</span> FaceAnalysis<span class=\"token punctuation\">(</span>providers<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'CUDAExecutionProvider'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>recognizer<span class=\"token punctuation\">.</span>prepare<span class=\"token punctuation\">(</span>ctx_id<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> det_size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">640</span><span class=\"token punctuation\">,</span> <span class=\"token number\">640</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Liveness: MediaPipe for landmark detection + custom anti-spoof model</span>\n        self<span class=\"token punctuation\">.</span>liveness_checker <span class=\"token operator\">=</span> LivenessDetector<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">verify</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> image<span class=\"token punctuation\">:</span> np<span class=\"token punctuation\">.</span>ndarray<span class=\"token punctuation\">,</span> enrolled_embedding<span class=\"token punctuation\">:</span> np<span class=\"token punctuation\">.</span>ndarray<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># Step 1: Detect faces</span>\n        faces <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>detector<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>faces<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span><span class=\"token string\">\"status\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"no_face_detected\"</span><span class=\"token punctuation\">}</span>\n\n        <span class=\"token comment\"># Step 2: Liveness check — reject spoofing attempts</span>\n        liveness_score <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>liveness_checker<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> faces<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> liveness_score <span class=\"token operator\">&lt;</span> LIVENESS_THRESHOLD<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span><span class=\"token string\">\"status\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"spoof_detected\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"confidence\"</span><span class=\"token punctuation\">:</span> liveness_score<span class=\"token punctuation\">}</span>\n\n        <span class=\"token comment\"># Step 3: Extract embedding and compare</span>\n        face_embedding <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>recognizer<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>embedding\n        similarity <span class=\"token operator\">=</span> cosine_similarity<span class=\"token punctuation\">(</span>face_embedding<span class=\"token punctuation\">,</span> enrolled_embedding<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">\"status\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"verified\"</span> <span class=\"token keyword\">if</span> similarity <span class=\"token operator\">></span> SIMILARITY_THRESHOLD <span class=\"token keyword\">else</span> <span class=\"token string\">\"not_matched\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"similarity\"</span><span class=\"token punctuation\">:</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span>similarity<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"liveness_score\"</span><span class=\"token punctuation\">:</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span>liveness_score<span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">}</span></code></pre></div>\n<h3>Fish Recognition: Domain-Specific Data Challenges</h3>\n<p>The fish classification system presented different challenges. The primary hurdle was <strong>data scarcity</strong> — getting labeled images of specific fish species in Indonesian waters at sufficient volume and quality.</p>\n<p>Our approach:</p>\n<ol>\n<li><strong>Data collection</strong> — partnered with KNMP to gather images from field surveys</li>\n<li><strong>Data augmentation</strong> — extensive augmentation pipeline (rotation, flipping, color jitter, Cutout) to artificially expand the dataset</li>\n<li><strong>Transfer learning</strong> — fine-tuned a pre-trained EfficientNet-B4 on our domain-specific dataset</li>\n<li><strong>Active learning</strong> — deployed a confidence-threshold-based system to flag uncertain predictions for human review</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Training with class imbalance handling</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">FishClassificationTrainer</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> num_classes<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>model <span class=\"token operator\">=</span> timm<span class=\"token punctuation\">.</span>create_model<span class=\"token punctuation\">(</span>\n            <span class=\"token string\">'efficientnet_b4'</span><span class=\"token punctuation\">,</span>\n            pretrained<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n            num_classes<span class=\"token operator\">=</span>num_classes\n        <span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">compute_class_weights</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> dataset<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> torch<span class=\"token punctuation\">.</span>Tensor<span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"Handle class imbalance with weighted sampling.\"\"\"</span>\n        class_counts <span class=\"token operator\">=</span> Counter<span class=\"token punctuation\">(</span>dataset<span class=\"token punctuation\">.</span>labels<span class=\"token punctuation\">)</span>\n        total <span class=\"token operator\">=</span> <span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>class_counts<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        weights <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>total <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>class_counts<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> class_counts<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n                   <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>class_counts<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">return</span> torch<span class=\"token punctuation\">.</span>FloatTensor<span class=\"token punctuation\">(</span>weights<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">train</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> train_loader<span class=\"token punctuation\">,</span> val_loader<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">50</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        class_weights <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>compute_class_weights<span class=\"token punctuation\">(</span>train_loader<span class=\"token punctuation\">.</span>dataset<span class=\"token punctuation\">)</span>\n        criterion <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>CrossEntropyLoss<span class=\"token punctuation\">(</span>weight<span class=\"token operator\">=</span>class_weights<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        optimizer <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>optim<span class=\"token punctuation\">.</span>AdamW<span class=\"token punctuation\">(</span>\n            self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span><span class=\"token number\">1e-4</span><span class=\"token punctuation\">,</span> weight_decay<span class=\"token operator\">=</span><span class=\"token number\">0.01</span>\n        <span class=\"token punctuation\">)</span>\n        scheduler <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>optim<span class=\"token punctuation\">.</span>lr_scheduler<span class=\"token punctuation\">.</span>CosineAnnealingLR<span class=\"token punctuation\">(</span>\n            optimizer<span class=\"token punctuation\">,</span> T_max<span class=\"token operator\">=</span>epochs\n        <span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># ... training loop</span></code></pre></div>\n<h2>Serving Architecture</h2>\n<p>Both systems needed to be served as REST APIs with low latency. The architecture we landed on:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">                          ┌─────────────────────────┐\n                          │     Load Balancer         │\n                          └──────────┬──────────────┘\n                                     │\n              ┌──────────────────────┼──────────────────────┐\n              ▼                      ▼                       ▼\n    ┌──────────────────┐  ┌──────────────────┐  ┌──────────────────┐\n    │   Django API     │  │   Django API     │  │   Django API     │\n    │  (Worker 1)      │  │  (Worker 2)      │  │  (Worker 3)      │\n    └────────┬─────────┘  └────────┬─────────┘  └────────┬─────────┘\n             │                     │                      │\n             └─────────────────────┼──────────────────────┘\n                                   │\n             ┌─────────────────────┼──────────────────────┐\n             ▼                     ▼                       ▼\n    ┌──────────────────┐  ┌──────────────────┐  ┌──────────────────┐\n    │  Model Server    │  │   PostgreSQL     │  │     Redis        │\n    │  (TorchServe)    │  │   (Embeddings)   │  │    (Cache)       │\n    └──────────────────┘  └──────────────────┘  └──────────────────┘</code></pre></div>\n<p><strong>Key decisions:</strong></p>\n<ul>\n<li><strong>TorchServe</strong> for dedicated model inference — separates the ML runtime from the Django app, enabling independent scaling</li>\n<li><strong>Redis</strong> for caching face embeddings — embedding lookup on every request would be prohibitively slow</li>\n<li><strong>PostgreSQL with pgvector</strong> for scalable similarity search across enrolled face embeddings</li>\n</ul>\n<h2>Performance Optimizations</h2>\n<h3>Model Quantization</h3>\n<p>For the face recognition model, INT8 quantization reduced model size by ~4x and inference time by ~2x with minimal accuracy degradation:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>quantization\n\n<span class=\"token comment\"># Post-training static quantization</span>\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>qconfig <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>quantization<span class=\"token punctuation\">.</span>get_default_qconfig<span class=\"token punctuation\">(</span><span class=\"token string\">'fbgemm'</span><span class=\"token punctuation\">)</span>\ntorch<span class=\"token punctuation\">.</span>quantization<span class=\"token punctuation\">.</span>prepare<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Calibration</span>\n<span class=\"token keyword\">with</span> torch<span class=\"token punctuation\">.</span>no_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> images<span class=\"token punctuation\">,</span> _ <span class=\"token keyword\">in</span> calibration_loader<span class=\"token punctuation\">:</span>\n        model<span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">)</span>\n\ntorch<span class=\"token punctuation\">.</span>quantization<span class=\"token punctuation\">.</span>convert<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3>Batch Processing</h3>\n<p>For the fish recognition API, requests are batched using an async queue to amortize GPU overhead:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">BatchInferenceQueue</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> max_batch_size<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> max_wait_ms<span class=\"token operator\">=</span><span class=\"token number\">50</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>queue <span class=\"token operator\">=</span> asyncio<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>max_batch_size <span class=\"token operator\">=</span> max_batch_size\n        self<span class=\"token punctuation\">.</span>max_wait_ms <span class=\"token operator\">=</span> max_wait_ms\n\n    <span class=\"token keyword\">async</span> <span class=\"token keyword\">def</span> <span class=\"token function\">predict</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> image<span class=\"token punctuation\">:</span> np<span class=\"token punctuation\">.</span>ndarray<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">:</span>\n        future <span class=\"token operator\">=</span> asyncio<span class=\"token punctuation\">.</span>Future<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">await</span> self<span class=\"token punctuation\">.</span>queue<span class=\"token punctuation\">.</span>put<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> future<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> <span class=\"token keyword\">await</span> future\n\n    <span class=\"token keyword\">async</span> <span class=\"token keyword\">def</span> <span class=\"token function\">process_batches</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">while</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">:</span>\n            batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n            deadline <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>monotonic<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>max_wait_ms <span class=\"token operator\">/</span> <span class=\"token number\">1000</span>\n\n            <span class=\"token keyword\">while</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>batch<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> self<span class=\"token punctuation\">.</span>max_batch_size<span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n                    timeout <span class=\"token operator\">=</span> <span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> deadline <span class=\"token operator\">-</span> time<span class=\"token punctuation\">.</span>monotonic<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                    item <span class=\"token operator\">=</span> <span class=\"token keyword\">await</span> asyncio<span class=\"token punctuation\">.</span>wait_for<span class=\"token punctuation\">(</span>\n                        self<span class=\"token punctuation\">.</span>queue<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> timeout<span class=\"token operator\">=</span>timeout\n                    <span class=\"token punctuation\">)</span>\n                    batch<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>item<span class=\"token punctuation\">)</span>\n                <span class=\"token keyword\">except</span> asyncio<span class=\"token punctuation\">.</span>TimeoutError<span class=\"token punctuation\">:</span>\n                    <span class=\"token keyword\">break</span>\n\n            <span class=\"token keyword\">if</span> batch<span class=\"token punctuation\">:</span>\n                images<span class=\"token punctuation\">,</span> futures <span class=\"token operator\">=</span> <span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>batch<span class=\"token punctuation\">)</span>\n                results <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict_batch<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>stack<span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                <span class=\"token keyword\">for</span> future<span class=\"token punctuation\">,</span> result <span class=\"token keyword\">in</span> <span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>futures<span class=\"token punctuation\">,</span> results<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                    future<span class=\"token punctuation\">.</span>set_result<span class=\"token punctuation\">(</span>result<span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Monitoring in Production</h2>\n<p>Both systems are monitored via:</p>\n<ul>\n<li><strong>Prometheus + Grafana</strong> for latency percentiles (p50, p95, p99) and throughput</li>\n<li><strong>Confidence score distribution tracking</strong> — a drop in average confidence often signals data drift</li>\n<li><strong>Rejection rate monitoring</strong> — for the face recognition system, a spike in anti-spoof rejections can indicate an attack attempt</li>\n</ul>\n<h2>Lessons Learned</h2>\n<ol>\n<li><strong>Liveness detection is non-negotiable for biometrics</strong> — without it, a printed photo can fool even a highly accurate recognition system</li>\n<li><strong>Data quality beats model complexity</strong> — 1000 high-quality, diverse training images outperform 10,000 noisy ones</li>\n<li><strong>Separate your ML runtime from your API</strong> — Django is excellent for the business logic; TorchServe handles the model serving</li>\n<li><strong>Cache aggressively</strong> — face embeddings, model outputs for known images, and preprocessing results can all be cached</li>\n<li><strong>Build with confidence thresholds, not binary outputs</strong> — returning a confidence score enables the application layer to handle edge cases gracefully</li>\n</ol>\n<hr>\n<p><em>This post is based on my work at Pt Bagus Harapan Tritunggal building production computer vision systems.</em></p>","frontmatter":{"title":"Building Enterprise Computer Vision Systems: From Research to Production","description":"Key architectural decisions and lessons learned from deploying face recognition and fish classification systems at scale in production environments.","date":"2025-12-10","slug":"/pensieve/computer-vision-production","tags":["Computer Vision","Python","Django","Machine Learning","PyTorch"]}}},"pageContext":{"slug":"/pensieve/computer-vision-production"}},"staticQueryHashes":["3115057458"],"slicesMap":{}}
{"componentChunkName":"component---src-templates-post-js","path":"/pensieve/building-agentic-ai-systems/","result":{"data":{"markdownRemark":{"html":"<h2>Introduction</h2>\n<p>Agentic AI — systems where LLMs act as autonomous reasoning engines that plan, use tools, and execute multi-step workflows — is rapidly moving from research curiosity to production reality. I had the unique opportunity to build an <strong>AI Policy Simulator</strong> for Indonesia's Ministry of Law and Human Rights (Kemenkumham), a system that enables government officials to model the potential real-world impacts of new legal policies before they're officially enacted.</p>\n<p>This post covers the architecture, key design decisions, and lessons learned from building a production agentic AI system for a high-stakes government use case.</p>\n<h2>The Problem: Policy Impact Simulation</h2>\n<p>Before a new regulation is enacted within the AHU Online ecosystem (Indonesia's legal entity management system), decision-makers need answers to complex questions:</p>\n<ul>\n<li>\"If we introduce this new compliance requirement, how many businesses will be affected?\"</li>\n<li>\"What's the estimated processing time impact on current AHU workflows?\"</li>\n<li>\"Are there conflicting regulations this new policy would interact with?\"</li>\n</ul>\n<p>These questions require reasoning over large document corpora, structured databases, and historical workflow data — exactly the kind of multi-step, tool-augmented reasoning that agentic AI excels at.</p>\n<h2>Architecture: The Multi-Agent Approach</h2>\n<p>Rather than a single monolithic LLM chain, we used a <strong>multi-agent architecture</strong> where specialized agents handle different aspects of the simulation:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">User Query\n    │\n    ▼\n┌─────────────────────────────────────────────────────┐\n│                  Orchestrator Agent                   │\n│  (Plans the simulation, delegates to sub-agents)     │\n└──────────┬──────────────────────────────────────────┘\n           │\n    ┌──────┴──────┐\n    │             │\n    ▼             ▼\n┌────────┐   ┌────────────┐\n│ Legal  │   │ Workflow   │\n│ Analyst│   │ Analyst    │\n│ Agent  │   │ Agent      │\n└────┬───┘   └─────┬──────┘\n     │              │\n     ▼              ▼\n Document      Database\n Retrieval     Queries\n (RAG)         (SQL)</code></pre></div>\n<h3>The Orchestrator</h3>\n<p>The orchestrator uses an LLM (Llama 3 via Ollama) to break down the user's policy question into a simulation plan:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> langchain<span class=\"token punctuation\">.</span>agents <span class=\"token keyword\">import</span> AgentExecutor<span class=\"token punctuation\">,</span> create_openai_tools_agent\n<span class=\"token keyword\">from</span> langchain_core<span class=\"token punctuation\">.</span>prompts <span class=\"token keyword\">import</span> ChatPromptTemplate<span class=\"token punctuation\">,</span> MessagesPlaceholder\n\nORCHESTRATOR_SYSTEM <span class=\"token operator\">=</span> <span class=\"token triple-quoted-string string\">\"\"\"You are a policy simulation orchestrator for the Indonesian\nMinistry of Law. Given a proposed policy, create a structured simulation plan by:\n1. Identifying what aspects of the AHU system would be affected\n2. Estimating the scope of impact (number of affected entities)\n3. Analyzing potential conflicts with existing regulations\n4. Projecting workflow changes and processing time impacts\n\nUse the available tools to gather data and reason systematically.\"\"\"</span>\n\nprompt <span class=\"token operator\">=</span> ChatPromptTemplate<span class=\"token punctuation\">.</span>from_messages<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">\"system\"</span><span class=\"token punctuation\">,</span> ORCHESTRATOR_SYSTEM<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    MessagesPlaceholder<span class=\"token punctuation\">(</span>variable_name<span class=\"token operator\">=</span><span class=\"token string\">\"chat_history\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">\"human\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"{input}\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    MessagesPlaceholder<span class=\"token punctuation\">(</span>variable_name<span class=\"token operator\">=</span><span class=\"token string\">\"agent_scratchpad\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\norchestrator <span class=\"token operator\">=</span> create_openai_tools_agent<span class=\"token punctuation\">(</span>llm<span class=\"token punctuation\">,</span> tools<span class=\"token punctuation\">,</span> prompt<span class=\"token punctuation\">)</span>\norchestrator_executor <span class=\"token operator\">=</span> AgentExecutor<span class=\"token punctuation\">(</span>\n    agent<span class=\"token operator\">=</span>orchestrator<span class=\"token punctuation\">,</span>\n    tools<span class=\"token operator\">=</span>tools<span class=\"token punctuation\">,</span>\n    verbose<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n    max_iterations<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span>\n    handle_parsing_errors<span class=\"token operator\">=</span><span class=\"token boolean\">True</span>\n<span class=\"token punctuation\">)</span></code></pre></div>\n<h3>Tools: The Bridge to Real Data</h3>\n<p>The power of the agentic approach comes from tools — functions the LLM can call to interact with real systems:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> langchain<span class=\"token punctuation\">.</span>tools <span class=\"token keyword\">import</span> tool\n<span class=\"token keyword\">from</span> django<span class=\"token punctuation\">.</span>db <span class=\"token keyword\">import</span> connection\n\n<span class=\"token decorator annotation punctuation\">@tool</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">query_affected_entities</span><span class=\"token punctuation\">(</span>policy_type<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> criteria<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Query the AHU database to count entities affected by a policy change.\n\n    Args:\n        policy_type: Type of legal entity affected (PT, CV, Yayasan, etc.)\n        criteria: SQL-safe criteria string for filtering entities\n\n    Returns:\n        JSON string with count and representative sample of affected entities\n    \"\"\"</span>\n    <span class=\"token keyword\">with</span> connection<span class=\"token punctuation\">.</span>cursor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> cursor<span class=\"token punctuation\">:</span>\n        cursor<span class=\"token punctuation\">.</span>execute<span class=\"token punctuation\">(</span><span class=\"token triple-quoted-string string\">\"\"\"\n            SELECT entity_type, COUNT(*) as count,\n                   AVG(processing_days) as avg_processing\n            FROM ahu_entities\n            WHERE entity_type = %s AND %s\n            GROUP BY entity_type\n        \"\"\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>policy_type<span class=\"token punctuation\">,</span> criteria<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        results <span class=\"token operator\">=</span> cursor<span class=\"token punctuation\">.</span>fetchall<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> json<span class=\"token punctuation\">.</span>dumps<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span><span class=\"token string\">\"affected_count\"</span><span class=\"token punctuation\">:</span> results<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"avg_days\"</span><span class=\"token punctuation\">:</span> results<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token decorator annotation punctuation\">@tool</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">search_regulations</span><span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Semantic search over the regulation document corpus.\n\n    Args:\n        query: Natural language query about regulations\n\n    Returns:\n        Top 3 most relevant regulation excerpts with source citations\n    \"\"\"</span>\n    results <span class=\"token operator\">=</span> regulation_rag<span class=\"token punctuation\">.</span>retrieve<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">,</span> top_k<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> json<span class=\"token punctuation\">.</span>dumps<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n        <span class=\"token punctuation\">{</span><span class=\"token string\">\"content\"</span><span class=\"token punctuation\">:</span> r<span class=\"token punctuation\">[</span><span class=\"token string\">\"content\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"source\"</span><span class=\"token punctuation\">:</span> r<span class=\"token punctuation\">[</span><span class=\"token string\">\"metadata\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"doc_id\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">for</span> r <span class=\"token keyword\">in</span> results\n    <span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token decorator annotation punctuation\">@tool</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">simulate_workflow_impact</span><span class=\"token punctuation\">(</span>change_description<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Run a workflow simulation to estimate processing time impact.\n\n    Args:\n        change_description: Description of the workflow change\n\n    Returns:\n        Estimated delta in processing time and bottleneck analysis\n    \"\"\"</span>\n    <span class=\"token keyword\">return</span> workflow_simulator<span class=\"token punctuation\">.</span>estimate_impact<span class=\"token punctuation\">(</span>change_description<span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Handling the Challenges of Agentic AI in Production</h2>\n<h3>1. Grounding and Hallucination Prevention</h3>\n<p>Government systems have zero tolerance for hallucinated data. We implemented multiple guardrails:</p>\n<ul>\n<li><strong>Mandatory tool use for data claims</strong>: The system prompt explicitly instructs the agent to use tools for any numerical claim, never to estimate from memory</li>\n<li><strong>Citation tracking</strong>: Every factual claim in the output is traced back to a tool call result</li>\n<li><strong>Output validation</strong>: A separate \"critic\" LLM call validates the final output against the tool call history</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">validate_simulation_output</span><span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> tool_calls<span class=\"token punctuation\">:</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Verify all claims in the output are grounded in tool call results.\"\"\"</span>\n    critic_prompt <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"\"\"Given this simulation output and the supporting data from tool calls,\nidentify any claims that are NOT supported by the tool call results.\n\nOutput: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>output<span class=\"token punctuation\">}</span></span><span class=\"token string\">\nTool Results: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>json<span class=\"token punctuation\">.</span>dumps<span class=\"token punctuation\">(</span>tool_calls<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\n\nList any unsupported claims or respond with \"VALIDATED\" if all claims are grounded.\"\"\"</span></span>\n\n    validation <span class=\"token operator\">=</span> critic_llm<span class=\"token punctuation\">.</span>invoke<span class=\"token punctuation\">(</span>critic_prompt<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span><span class=\"token string\">\"valid\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"VALIDATED\"</span> <span class=\"token keyword\">in</span> validation<span class=\"token punctuation\">.</span>content<span class=\"token punctuation\">,</span> <span class=\"token string\">\"issues\"</span><span class=\"token punctuation\">:</span> validation<span class=\"token punctuation\">.</span>content<span class=\"token punctuation\">}</span></code></pre></div>\n<h3>2. Cost and Latency Management</h3>\n<p>Agentic AI systems can make many LLM calls per request. We managed this with:</p>\n<ul>\n<li><strong>Tool call caching</strong>: Results of expensive DB queries are cached for the session duration</li>\n<li><strong>Early termination</strong>: If the agent reaches a confident conclusion early, it stops before exhausting its iteration budget</li>\n<li><strong>Streaming</strong>: We stream the agent's \"thinking\" to the frontend so users see progress during long simulations</li>\n</ul>\n<h3>3. MCP (Model Context Protocol) Integration</h3>\n<p>For structured data exchange between the Django backend and the Ollama model server, we used MCP (Anthropic's Model Context Protocol). This standardizes how the application exposes tools and resources to the model:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># MCP server exposing AHU data resources</span>\n<span class=\"token keyword\">from</span> mcp<span class=\"token punctuation\">.</span>server<span class=\"token punctuation\">.</span>fastmcp <span class=\"token keyword\">import</span> FastMCP\n\nmcp <span class=\"token operator\">=</span> FastMCP<span class=\"token punctuation\">(</span><span class=\"token string\">\"AHU Policy Simulator\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token decorator annotation punctuation\">@mcp<span class=\"token punctuation\">.</span>resource</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"ahu://entities/{entity_type}\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">get_entity_stats</span><span class=\"token punctuation\">(</span>entity_type<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Get statistics for a specific AHU entity type.\"\"\"</span>\n    stats <span class=\"token operator\">=</span> Entity<span class=\"token punctuation\">.</span>objects<span class=\"token punctuation\">.</span><span class=\"token builtin\">filter</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">type</span><span class=\"token operator\">=</span>entity_type<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>aggregate<span class=\"token punctuation\">(</span>\n        count<span class=\"token operator\">=</span>Count<span class=\"token punctuation\">(</span><span class=\"token string\">'id'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        avg_processing_days<span class=\"token operator\">=</span>Avg<span class=\"token punctuation\">(</span><span class=\"token string\">'processing_days'</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> json<span class=\"token punctuation\">.</span>dumps<span class=\"token punctuation\">(</span>stats<span class=\"token punctuation\">)</span>\n\n<span class=\"token decorator annotation punctuation\">@mcp<span class=\"token punctuation\">.</span>tool</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">run_compliance_check</span><span class=\"token punctuation\">(</span>policy_text<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Check a proposed policy against existing regulations for conflicts.\"\"\"</span>\n    conflicts <span class=\"token operator\">=</span> find_regulatory_conflicts<span class=\"token punctuation\">(</span>policy_text<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span><span class=\"token string\">\"conflicts\"</span><span class=\"token punctuation\">:</span> conflicts<span class=\"token punctuation\">,</span> <span class=\"token string\">\"severity\"</span><span class=\"token punctuation\">:</span> assess_severity<span class=\"token punctuation\">(</span>conflicts<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></code></pre></div>\n<h2>Key Lessons for Production Agentic AI</h2>\n<ol>\n<li><strong>Start with a bounded task</strong> — don't give the agent unlimited scope; define clear entry/exit conditions</li>\n<li><strong>Tool design is as important as model selection</strong> — well-designed tools with clear docstrings dramatically improve reliability</li>\n<li><strong>Always validate before presenting to users</strong> — especially in high-stakes domains like government policy</li>\n<li><strong>Log everything</strong> — every tool call, every LLM response; you need this for debugging and audit trails</li>\n<li><strong>Hybrid approaches work best</strong> — combine agentic reasoning for complex queries with rule-based systems for simple lookups</li>\n</ol>\n<h2>What's Next</h2>\n<p>We're exploring <strong>multi-modal policy simulation</strong> — incorporating document images, forms, and diagrams into the context alongside text. We're also building a <strong>feedback loop</strong> where government officials can correct simulation outputs, creating a fine-tuning dataset for domain adaptation.</p>\n<hr>\n<p><em>This post is based on my work at Pt Bagus Harapan Tritunggal building the AI Policy Simulator for Kemenkumham.</em></p>","frontmatter":{"title":"Building Agentic AI Systems: From LLM Chains to Autonomous Policy Simulators","description":"How we built an Agentic AI system for the Indonesian Ministry of Law to simulate and analyze the impact of new legal policies before enactment.","date":"2025-09-15","slug":"/pensieve/building-agentic-ai-systems","tags":["AI","Agentic AI","Langchain","LLM","Python"]}}},"pageContext":{"slug":"/pensieve/building-agentic-ai-systems"}},"staticQueryHashes":["3115057458"],"slicesMap":{}}